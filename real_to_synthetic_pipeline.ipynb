{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8596adc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'swellsight'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-3110110000.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mswellsight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmidas_depth_extractor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMiDaSDepthExtractor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mswellsight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrolnet_generator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mControlNetSyntheticGenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAugmentationParameterSystem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'swellsight'",
      "",
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Real Images to Synthetic Images Pipeline\n",
    "\n",
    "This script performs exactly what you requested:\n",
    "1. Use MiDaS model to extract depth maps from real images in data/real/images\n",
    "2. Perform data augmentation on these depth maps\n",
    "3. Produce synthetic images from these depth maps using ControlNet\n",
    "\n",
    "Usage:\n",
    "    python real_to_synthetic_pipeline.py --input data/real/images --output data/synthetic\n",
    "\"\"\"\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "from swellsight.data.midas_depth_extractor import MiDaSDepthExtractor\n",
    "from swellsight.data.controlnet_generator import ControlNetSyntheticGenerator, AugmentationParameterSystem\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description='Real Images to Synthetic Images Pipeline')\n",
    "    parser.add_argument('--input', '-i', required=True, help='Input directory with real beach images')\n",
    "    parser.add_argument('--output', '-o', required=True, help='Output directory for synthetic images')\n",
    "    parser.add_argument('--depth-output', default='data/depth_maps', help='Output directory for depth maps')\n",
    "    parser.add_argument('--midas-model', default='Intel/dpt-large', \n",
    "                       choices=['Intel/dpt-large', 'Intel/dpt-hybrid-midas', 'Intel/dpt-base'],\n",
    "                       help='MiDaS model to use')\n",
    "    parser.add_argument('--controlnet-model', default='lllyasviel/sd-controlnet-depth',\n",
    "                       help='ControlNet model to use')\n",
    "    parser.add_argument('--device', choices=['cuda', 'cpu'], help='Device to use (auto-detect if not specified)')\n",
    "    parser.add_argument('--quality-threshold', type=float, default=0.3, \n",
    "                       help='Minimum depth quality threshold (0.0-1.0)')\n",
    "    parser.add_argument('--synthetic-per-real', type=int, default=3,\n",
    "                       help='Number of synthetic images to generate per real image')\n",
    "    parser.add_argument('--max-images', type=int, default=50,\n",
    "                       help='Maximum number of images to process (default: 50)')\n",
    "    parser.add_argument('--batch-size', type=int, default=1, help='Batch size for processing')\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # Setup paths\n",
    "    input_path = Path(args.input)\n",
    "    output_path = Path(args.output)\n",
    "    depth_output_path = Path(args.depth_output)\n",
    "    \n",
    "    # Create output directories\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    depth_output_path.mkdir(parents=True, exist_ok=True)\n",
    "    (output_path / 'images').mkdir(exist_ok=True)\n",
    "    (output_path / 'labels').mkdir(exist_ok=True)\n",
    "    \n",
    "    if not input_path.exists():\n",
    "        logger.error(f\"Input directory does not exist: {input_path}\")\n",
    "        return 1\n",
    "    \n",
    "    # Find all image files\n",
    "    image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp']\n",
    "    image_paths = []\n",
    "    for ext in image_extensions:\n",
    "        image_paths.extend(input_path.glob(ext))\n",
    "        image_paths.extend(input_path.glob(ext.upper()))\n",
    "    \n",
    "    if not image_paths:\n",
    "        logger.error(f\"No image files found in {input_path}\")\n",
    "        return 1\n",
    "    \n",
    "    # Limit number of images to process\n",
    "    if len(image_paths) > args.max_images:\n",
    "        logger.info(f\"Limiting processing to {args.max_images} images (found {len(image_paths)})\")\n",
    "        image_paths = image_paths[:args.max_images]\n",
    "    \n",
    "    logger.info(f\"Processing {len(image_paths)} real images\")\n",
    "    \n",
    "    # STEP 1: Initialize MiDaS depth extractor\n",
    "    logger.info(\"Step 1: Initializing MiDaS depth extractor...\")\n",
    "    try:\n",
    "        depth_extractor = MiDaSDepthExtractor(\n",
    "            model_name=args.midas_model,\n",
    "            device=args.device,\n",
    "            storage_path=str(depth_output_path)\n",
    "        )\n",
    "        logger.info(f\"MiDaS depth extractor initialized with model: {args.midas_model}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to initialize MiDaS extractor: {e}\")\n",
    "        return 1\n",
    "    \n",
    "    # STEP 2: Initialize augmentation parameter system\n",
    "    logger.info(\"Step 2: Initializing augmentation parameter system...\")\n",
    "    try:\n",
    "        param_system = AugmentationParameterSystem()\n",
    "        logger.info(\"Augmentation parameter system initialized\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to initialize augmentation system: {e}\")\n",
    "        return 1\n",
    "    \n",
    "    # STEP 3: Initialize ControlNet generator\n",
    "    logger.info(\"Step 3: Initializing ControlNet synthetic generator...\")\n",
    "    try:\n",
    "        controlnet_config = {\n",
    "            'controlnet_model_name': args.controlnet_model,\n",
    "            'device': args.device,\n",
    "            'batch_size': args.batch_size,\n",
    "            'guidance_scale': 7.5,\n",
    "            'num_inference_steps': 20,\n",
    "            'controlnet_conditioning_scale': 1.0\n",
    "        }\n",
    "        \n",
    "        controlnet_generator = ControlNetSyntheticGenerator(controlnet_config)\n",
    "        logger.info(f\"ControlNet generator initialized with model: {args.controlnet_model}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to initialize ControlNet generator: {e}\")\n",
    "        return 1\n",
    "    \n",
    "    # Process each real image\n",
    "    total_synthetic_generated = 0\n",
    "    successful_real_images = 0\n",
    "    failed_real_images = 0\n",
    "    \n",
    "    synthetic_metadata = []\n",
    "    \n",
    "    for i, image_path in enumerate(image_paths):\n",
    "        logger.info(f\"\\nProcessing real image {i+1}/{len(image_paths)}: {image_path.name}\")\n",
    "        \n",
    "        try:\n",
    "            # STEP 1: Extract depth map from real image\n",
    "            logger.info(\"  Step 1: Extracting depth map with MiDaS...\")\n",
    "            depth_result = depth_extractor.extract_depth(str(image_path), store_result=True)\n",
    "            \n",
    "            # Check depth quality\n",
    "            if depth_result.depth_quality_score < args.quality_threshold:\n",
    "                logger.warning(f\"  Low quality depth map (score: {depth_result.depth_quality_score:.3f}), skipping\")\n",
    "                failed_real_images += 1\n",
    "                continue\n",
    "            \n",
    "            logger.info(f\"  Depth extraction successful (quality: {depth_result.depth_quality_score:.3f})\")\n",
    "            \n",
    "            # STEP 2: Generate augmented parameters for synthetic variations\n",
    "            logger.info(f\"  Step 2: Generating {args.synthetic_per_real} augmented parameter sets...\")\n",
    "            \n",
    "            for j in range(args.synthetic_per_real):\n",
    "                # Generate augmented parameters\n",
    "                augmentation_params = param_system.generate_random_parameters()\n",
    "                \n",
    "                logger.info(f\"    Generated augmentation parameters for variation {j+1}\")\n",
    "                \n",
    "                # STEP 3: Generate synthetic image using ControlNet\n",
    "                logger.info(f\"  Step 3: Generating synthetic image {j+1}/{args.synthetic_per_real}...\")\n",
    "                \n",
    "                try:\n",
    "                    synthetic_result = controlnet_generator.generate_synthetic_image(\n",
    "                        depth_map=depth_result.depth_map,\n",
    "                        augmentation_params=augmentation_params\n",
    "                    )\n",
    "                    \n",
    "                    # Save synthetic image\n",
    "                    synthetic_filename = f\"{image_path.stem}_synthetic_{j+1:03d}.jpg\"\n",
    "                    synthetic_image_path = output_path / 'images' / synthetic_filename\n",
    "                    \n",
    "                    # Convert numpy array to PIL Image and save\n",
    "                    if isinstance(synthetic_result.synthetic_image, np.ndarray):\n",
    "                        # Ensure the array is in the right format (0-255, uint8)\n",
    "                        if synthetic_result.synthetic_image.max() <= 1.0:\n",
    "                            synthetic_image_array = (synthetic_result.synthetic_image * 255).astype(np.uint8)\n",
    "                        else:\n",
    "                            synthetic_image_array = synthetic_result.synthetic_image.astype(np.uint8)\n",
    "                        \n",
    "                        from PIL import Image\n",
    "                        synthetic_image_pil = Image.fromarray(synthetic_image_array)\n",
    "                        synthetic_image_pil.save(synthetic_image_path)\n",
    "                    else:\n",
    "                        # If it's already a PIL Image\n",
    "                        synthetic_result.synthetic_image.save(synthetic_image_path)\n",
    "                    \n",
    "                    # Create metadata\n",
    "                    sample_metadata = {\n",
    "                        'sample_id': f\"real_to_synthetic_{total_synthetic_generated:06d}\",\n",
    "                        'original_real_image': str(image_path),\n",
    "                        'synthetic_image_path': str(synthetic_image_path),\n",
    "                        'depth_map_quality': depth_result.depth_quality_score,\n",
    "                        'augmentation_params': augmentation_params.__dict__ if hasattr(augmentation_params, '__dict__') else augmentation_params,\n",
    "                        'generation_metadata': synthetic_result.generation_metadata,\n",
    "                        'quality_score': synthetic_result.quality_score,\n",
    "                        'created_timestamp': datetime.now().isoformat(),\n",
    "                        'pipeline_version': '1.0'\n",
    "                    }\n",
    "                    \n",
    "                    synthetic_metadata.append(sample_metadata)\n",
    "                    total_synthetic_generated += 1\n",
    "                    \n",
    "                    logger.info(f\"    Synthetic image saved: {synthetic_image_path}\")\n",
    "                \n",
    "                except Exception as e:\n",
    "                    logger.error(f\"    Error generating synthetic image {j+1}: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            successful_real_images += 1\n",
    "            logger.info(f\"  Successfully processed real image: {image_path.name}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"  Failed to process real image {image_path}: {e}\")\n",
    "            failed_real_images += 1\n",
    "            continue\n",
    "    \n",
    "    # Save metadata\n",
    "    metadata_file = output_path / 'synthetic_metadata.json'\n",
    "    with open(metadata_file, 'w') as f:\n",
    "        json.dump(synthetic_metadata, f, indent=2)\n",
    "    \n",
    "    # Generate summary report\n",
    "    summary = {\n",
    "        'pipeline_execution': {\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'input_path': str(input_path),\n",
    "            'output_path': str(output_path),\n",
    "            'midas_model': args.midas_model,\n",
    "            'controlnet_model': args.controlnet_model\n",
    "        },\n",
    "        'processing_results': {\n",
    "            'total_real_images': len(image_paths),\n",
    "            'successful_real_images': successful_real_images,\n",
    "            'failed_real_images': failed_real_images,\n",
    "            'total_synthetic_generated': total_synthetic_generated,\n",
    "            'synthetic_per_real_target': args.synthetic_per_real\n",
    "        },\n",
    "        'quality_metrics': {\n",
    "            'depth_quality_threshold': args.quality_threshold,\n",
    "            'success_rate': successful_real_images / len(image_paths) if image_paths else 0,\n",
    "            'synthetic_generation_rate': total_synthetic_generated / (successful_real_images * args.synthetic_per_real) if successful_real_images > 0 else 0\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    summary_file = output_path / 'pipeline_summary.json'\n",
    "    with open(summary_file, 'w') as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "    \n",
    "    # Print final summary\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"REAL TO SYNTHETIC PIPELINE COMPLETED\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Real images processed: {successful_real_images}/{len(image_paths)}\")\n",
    "    print(f\"Synthetic images generated: {total_synthetic_generated}\")\n",
    "    print(f\"Success rate: {successful_real_images/len(image_paths)*100:.1f}%\")\n",
    "    print(f\"Output directory: {output_path}\")\n",
    "    print(f\"Depth maps saved to: {depth_output_path}\")\n",
    "    print(f\"Metadata saved to: {metadata_file}\")\n",
    "    print(f\"Summary saved to: {summary_file}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return 0\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    exit(main())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
