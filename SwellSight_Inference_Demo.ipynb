{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SwellSight Wave Analysis - Inference and Evaluation\n",
    "\n",
    "## Interactive Inference Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveInferenceEngine:\n",
    "    \"\"\"Interactive inference engine for wave analysis.\"\"\"\n",
    "    \n",
    "    def __init__(self, model_path, device='cuda'):\n",
    "        self.device = device\n",
    "        self.model = None\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((768, 768)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        # Load model\n",
    "        self.load_model(model_path)\n",
    "    \n",
    "    def load_model(self, model_path):\n",
    "        \"\"\"Load trained model from checkpoint.\"\"\"\n",
    "        checkpoint = torch.load(model_path, map_location=self.device)\n",
    "        \n",
    "        # Recreate model\n",
    "        config = checkpoint['config']\n",
    "        self.model = WaveAnalysisModel(config).to(self.device)\n",
    "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        self.model.eval()\n",
    "        \n",
    "        print(f\"‚úÖ Model loaded from {model_path}\")\n",
    "        print(f\"üìä Validation loss: {checkpoint['val_loss']['total_loss']:.4f}\")\n",
    "    \n",
    "    def predict_image(self, image):\n",
    "        \"\"\"Predict wave parameters from image.\"\"\"\n",
    "        # Preprocess image\n",
    "        if isinstance(image, np.ndarray):\n",
    "            image = Image.fromarray(image)\n",
    "        \n",
    "        image_tensor = self.transform(image).unsqueeze(0).to(self.device)\n",
    "        \n",
    "        # Inference\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(image_tensor)\n",
    "        \n",
    "        # Process outputs\n",
    "        height = outputs['height'].cpu().item()\n",
    "        wave_type_probs = outputs['wave_type_probs'].cpu().numpy()[0]\n",
    "        direction_probs = outputs['direction_probs'].cpu().numpy()[0]\n",
    "        \n",
    "        # Get predictions\n",
    "        wave_type_idx = np.argmax(wave_type_probs)\n",
    "        direction_idx = np.argmax(direction_probs)\n",
    "        \n",
    "        return {\n",
    "            'height_meters': height,\n",
    "            'wave_type': WAVE_TYPES[wave_type_idx],\n",
    "            'direction': DIRECTIONS[direction_idx],\n",
    "            'wave_type_confidence': wave_type_probs[wave_type_idx],\n",
    "            'direction_confidence': direction_probs[direction_idx],\n",
    "            'wave_type_probs': {WAVE_TYPES[i]: prob for i, prob in enumerate(wave_type_probs)},\n",
    "            'direction_probs': {DIRECTIONS[i]: prob for i, prob in enumerate(direction_probs)}\n",
    "        }\n",
    "    \n",
    "    def visualize_prediction(self, image, prediction):\n",
    "        \"\"\"Visualize prediction results.\"\"\"\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "        \n",
    "        # Original image\n",
    "        axes[0].imshow(image)\n",
    "        axes[0].set_title('Input Image')\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        # Wave type probabilities\n",
    "        wave_types = list(prediction['wave_type_probs'].keys())\n",
    "        wave_probs = list(prediction['wave_type_probs'].values())\n",
    "        \n",
    "        bars1 = axes[1].bar(wave_types, wave_probs, color='skyblue')\n",
    "        axes[1].set_title('Wave Type Probabilities')\n",
    "        axes[1].set_ylabel('Probability')\n",
    "        axes[1].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Highlight predicted class\n",
    "        max_idx = np.argmax(wave_probs)\n",
    "        bars1[max_idx].set_color('orange')\n",
    "        \n",
    "        # Direction probabilities\n",
    "        directions = list(prediction['direction_probs'].keys())\n",
    "        dir_probs = list(prediction['direction_probs'].values())\n",
    "        \n",
    "        bars2 = axes[2].bar(directions, dir_probs, color='lightgreen')\n",
    "        axes[2].set_title('Direction Probabilities')\n",
    "        axes[2].set_ylabel('Probability')\n",
    "        \n",
    "        # Highlight predicted class\n",
    "        max_idx = np.argmax(dir_probs)\n",
    "        bars2[max_idx].set_color('red')\n",
    "        \n",
    "        # Add prediction text\n",
    "        plt.suptitle(\n",
    "            f\"Prediction: {prediction['height_meters']:.2f}m, {prediction['wave_type']}, {prediction['direction']}\\n\"\n",
    "            f\"Confidence: Type {prediction['wave_type_confidence']:.3f}, Direction {prediction['direction_confidence']:.3f}\",\n",
    "            fontsize=14, fontweight='bold'\n",
    "        )\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Load the trained model\n",
    "inference_engine = WaveInferenceEngine(checkpoints_dir / 'best_model.pth', device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive demo with synthetic samples\n",
    "def demo_inference(num_samples=5):\n",
    "    \"\"\"Demo inference on synthetic samples.\"\"\"\n",
    "    print(\"üåä SwellSight Wave Analysis Demo\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Generate test samples\n",
    "    test_generator = SyntheticDataGenerator()\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        print(f\"\\nüì∏ Sample {i+1}/{num_samples}\")\n",
    "        \n",
    "        # Generate sample\n",
    "        image, true_labels, params = test_generator.generate_sample()\n",
    "        \n",
    "        # Make prediction\n",
    "        prediction = inference_engine.predict_image(image)\n",
    "        \n",
    "        # Show results\n",
    "        print(f\"Ground Truth: {params['height_meters']:.2f}m, {params['wave_type']}, {params['direction']}\")\n",
    "        print(f\"Prediction:   {prediction['height_meters']:.2f}m, {prediction['wave_type']}, {prediction['direction']}\")\n",
    "        \n",
    "        # Calculate errors\n",
    "        height_error = abs(prediction['height_meters'] - params['height_meters'])\n",
    "        type_correct = prediction['wave_type'] == params['wave_type']\n",
    "        dir_correct = prediction['direction'] == params['direction']\n",
    "        \n",
    "        print(f\"Height Error: {height_error:.3f}m\")\n",
    "        print(f\"Type Correct: {'‚úÖ' if type_correct else '‚ùå'}\")\n",
    "        print(f\"Direction Correct: {'‚úÖ' if dir_correct else '‚ùå'}\")\n",
    "        \n",
    "        # Visualize\n",
    "        inference_engine.visualize_prediction(image, prediction)\n",
    "\n",
    "# Run demo\n",
    "demo_inference(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    \"\"\"Comprehensive model evaluation.\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    all_height_preds = []\n",
    "    all_height_true = []\n",
    "    all_type_preds = []\n",
    "    all_type_true = []\n",
    "    all_dir_preds = []\n",
    "    all_dir_true = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, targets in tqdm(test_loader, desc='Evaluating'):\n",
    "            images = images.to(device)\n",
    "            targets = {k: v.to(device) for k, v in targets.items()}\n",
    "            \n",
    "            outputs = model(images)\n",
    "            \n",
    "            # Collect predictions\n",
    "            all_height_preds.extend(outputs['height'].cpu().numpy())\n",
    "            all_height_true.extend(targets['height'].cpu().numpy())\n",
    "            \n",
    "            all_type_preds.extend(outputs['wave_type_logits'].argmax(dim=1).cpu().numpy())\n",
    "            all_type_true.extend(targets['wave_type'].cpu().numpy())\n",
    "            \n",
    "            all_dir_preds.extend(outputs['direction_logits'].argmax(dim=1).cpu().numpy())\n",
    "            all_dir_true.extend(targets['direction'].cpu().numpy())\n",
    "    \n",
    "    # Convert to numpy arrays\n",
    "    height_preds = np.array(all_height_preds)\n",
    "    height_true = np.array(all_height_true)\n",
    "    type_preds = np.array(all_type_preds)\n",
    "    type_true = np.array(all_type_true)\n",
    "    dir_preds = np.array(all_dir_preds)\n",
    "    dir_true = np.array(all_dir_true)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        'height_mae': np.mean(np.abs(height_preds - height_true)),\n",
    "        'height_rmse': np.sqrt(np.mean((height_preds - height_true) ** 2)),\n",
    "        'type_accuracy': accuracy_score(type_true, type_preds),\n",
    "        'type_f1': f1_score(type_true, type_preds, average='weighted'),\n",
    "        'direction_accuracy': accuracy_score(dir_true, dir_preds),\n",
    "        'direction_f1': f1_score(dir_true, dir_preds, average='weighted')\n",
    "    }\n",
    "    \n",
    "    return metrics, {\n",
    "        'height_preds': height_preds,\n",
    "        'height_true': height_true,\n",
    "        'type_preds': type_preds,\n",
    "        'type_true': type_true,\n",
    "        'dir_preds': dir_preds,\n",
    "        'dir_true': dir_true\n",
    "    }\n",
    "\n",
    "def plot_evaluation_results(metrics, predictions):\n",
    "    \"\"\"Plot comprehensive evaluation results.\"\"\"\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "    \n",
    "    # Height regression scatter plot\n",
    "    axes[0, 0].scatter(predictions['height_true'], predictions['height_preds'], alpha=0.6)\n",
    "    axes[0, 0].plot([0, 4], [0, 4], 'r--', label='Perfect prediction')\n",
    "    axes[0, 0].set_xlabel('True Height (m)')\n",
    "    axes[0, 0].set_ylabel('Predicted Height (m)')\n",
    "    axes[0, 0].set_title(f'Height Prediction\\nMAE: {metrics[\"height_mae\"]:.3f}m, RMSE: {metrics[\"height_rmse\"]:.3f}m')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True)\n",
    "    \n",
    "    # Height error distribution\n",
    "    height_errors = predictions['height_preds'] - predictions['height_true']\n",
    "    axes[0, 1].hist(height_errors, bins=30, alpha=0.7, color='skyblue')\n",
    "    axes[0, 1].axvline(0, color='red', linestyle='--', label='Perfect prediction')\n",
    "    axes[0, 1].set_xlabel('Prediction Error (m)')\n",
    "    axes[0, 1].set_ylabel('Frequency')\n",
    "    axes[0, 1].set_title('Height Prediction Error Distribution')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True)\n",
    "    \n",
    "    # Wave type confusion matrix\n",
    "    type_cm = confusion_matrix(predictions['type_true'], predictions['type_preds'])\n",
    "    sns.heatmap(type_cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=WAVE_TYPES, yticklabels=WAVE_TYPES, ax=axes[0, 2])\n",
    "    axes[0, 2].set_title(f'Wave Type Confusion Matrix\\nAccuracy: {metrics[\"type_accuracy\"]:.3f}, F1: {metrics[\"type_f1\"]:.3f}')\n",
    "    axes[0, 2].set_xlabel('Predicted')\n",
    "    axes[0, 2].set_ylabel('True')\n",
    "    \n",
    "    # Direction confusion matrix\n",
    "    dir_cm = confusion_matrix(predictions['dir_true'], predictions['dir_preds'])\n",
    "    sns.heatmap(dir_cm, annot=True, fmt='d', cmap='Greens',\n",
    "                xticklabels=DIRECTIONS, yticklabels=DIRECTIONS, ax=axes[1, 0])\n",
    "    axes[1, 0].set_title(f'Direction Confusion Matrix\\nAccuracy: {metrics[\"direction_accuracy\"]:.3f}, F1: {metrics[\"direction_f1\"]:.3f}')\n",
    "    axes[1, 0].set_xlabel('Predicted')\n",
    "    axes[1, 0].set_ylabel('True')\n",
    "    \n",
    "    # Metrics summary\n",
    "    axes[1, 1].axis('off')\n",
    "    metrics_text = f\"\"\"\n",
    "    üìä Model Performance Summary\n",
    "    \n",
    "    Height Regression:\n",
    "    ‚Ä¢ MAE: {metrics['height_mae']:.3f} meters\n",
    "    ‚Ä¢ RMSE: {metrics['height_rmse']:.3f} meters\n",
    "    \n",
    "    Wave Type Classification:\n",
    "    ‚Ä¢ Accuracy: {metrics['type_accuracy']:.3f}\n",
    "    ‚Ä¢ F1-Score: {metrics['type_f1']:.3f}\n",
    "    \n",
    "    Direction Classification:\n",
    "    ‚Ä¢ Accuracy: {metrics['direction_accuracy']:.3f}\n",
    "    ‚Ä¢ F1-Score: {metrics['direction_f1']:.3f}\n",
    "    \"\"\"\n",
    "    axes[1, 1].text(0.1, 0.5, metrics_text, fontsize=12, verticalalignment='center')\n",
    "    \n",
    "    # Performance by height range\n",
    "    height_ranges = [(0, 1), (1, 2), (2, 3), (3, 4)]\n",
    "    range_maes = []\n",
    "    range_labels = []\n",
    "    \n",
    "    for low, high in height_ranges:\n",
    "        mask = (predictions['height_true'] >= low) & (predictions['height_true'] < high)\n",
    "        if mask.sum() > 0:\n",
    "            range_mae = np.mean(np.abs(predictions['height_preds'][mask] - predictions['height_true'][mask]))\n",
    "            range_maes.append(range_mae)\n",
    "            range_labels.append(f'{low}-{high}m')\n",
    "    \n",
    "    axes[1, 2].bar(range_labels, range_maes, color='coral')\n",
    "    axes[1, 2].set_xlabel('Height Range')\n",
    "    axes[1, 2].set_ylabel('MAE (meters)')\n",
    "    axes[1, 2].set_title('Height Prediction Error by Range')\n",
    "    axes[1, 2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Evaluate on validation set\n",
    "print(\"üîç Evaluating model performance...\")\n",
    "metrics, predictions = evaluate_model(model, val_loader, device)\n",
    "plot_evaluation_results(metrics, predictions)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}