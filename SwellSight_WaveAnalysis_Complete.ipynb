{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# SwellSight Wave Analysis Model - Complete Implementation\n",
    "\n",
    "This notebook implements a multi-task deep learning model for extracting objective wave parameters from beach camera images.\n",
    "\n",
    "## Features\n",
    "- Multi-task architecture: Height regression + Wave type + Direction classification\n",
    "- ConvNeXt backbone with GPU acceleration\n",
    "- Synthetic data generation using existing depth maps + ControlNet\n",
    "- Real-time training monitoring and visualization\n",
    "- Interactive inference interface\n",
    "- Google Drive integration for persistence\n",
    "\n",
    "## Requirements\n",
    "- Google Colab with GPU runtime (T4/V100/A100)\n",
    "- Google Drive for data persistence\n",
    "- Existing SwellSight depth map generation code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## 1. Environment Setup and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_packages"
   },
   "outputs": [],
   "source": [
    "# Install required packages for Colab\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install timm transformers diffusers accelerate\n",
    "!pip install hypothesis opencv-python matplotlib seaborn plotly\n",
    "!pip install ipywidgets tqdm scikit-learn\n",
    "!pip install torchviz graphviz"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imports_and_setup"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import timm\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check GPU availability\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mount_drive"
   },
   "outputs": [],
   "source": [
    "# Mount Google Drive for data persistence\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create directory structure\n",
    "base_dir = Path('/content/drive/MyDrive/SwellSight')\n",
    "data_dir = base_dir / 'data'\n",
    "models_dir = base_dir / 'models'\n",
    "checkpoints_dir = base_dir / 'checkpoints'\n",
    "results_dir = base_dir / 'results'\n",
    "\n",
    "for dir_path in [base_dir, data_dir, models_dir, checkpoints_dir, results_dir]:\n",
    "    dir_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "print(f\"Created directories in: {base_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "depth_generation"
   },
   "source": [
    "## 2. Depth Map Generation (Existing Code Integration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "depth_map_functions"
   },
   "outputs": [],
   "source": [
    "# Copy existing depth map generation functions from SwellSight.ipynb\n",
    "# (This integrates your existing code)\n",
    "\n",
    "def look_at(eye, target, up=np.array([0, 0, 1.0], dtype=np.float32)):\n",
    "    \"\"\"Returns world->camera rotation R and translation t.\"\"\"\n",
    "    eye = eye.astype(np.float32)\n",
    "    target = target.astype(np.float32)\n",
    "    up = up.astype(np.float32)\n",
    "\n",
    "    f = target - eye\n",
    "    f = f / (np.linalg.norm(f) + 1e-8)\n",
    "\n",
    "    r = np.cross(f, up)\n",
    "    r = r / (np.linalg.norm(r) + 1e-8)\n",
    "\n",
    "    u = np.cross(r, f)\n",
    "    u = u / (np.linalg.norm(u) + 1e-8)\n",
    "\n",
    "    R = np.stack([r, u, f], axis=0).astype(np.float32)\n",
    "    t = -R @ eye\n",
    "    return R, t\n",
    "\n",
    "def gerstner_like_height(X, Y, waves, t=0.0):\n",
    "    \"\"\"Multi-sine height field for wave generation.\"\"\"\n",
    "    H = np.zeros_like(X, dtype=np.float32)\n",
    "    for w in waves:\n",
    "        A = float(w.get(\"amp\", 0.5))\n",
    "        lam = float(w.get(\"wavelength\", 12.0))\n",
    "        theta = float(w.get(\"direction\", 0.0))\n",
    "        phase = float(w.get(\"phase\", 0.0))\n",
    "        speed = float(w.get(\"speed\", 4.0))\n",
    "        k = 2.0 * np.pi / (lam + 1e-6)\n",
    "        dx, dy = np.cos(theta), np.sin(theta)\n",
    "        arg = k * (dx * X + dy * Y) - (k * speed) * t + phase\n",
    "        H += A * np.sin(arg).astype(np.float32)\n",
    "    return H\n",
    "\n",
    "# Add other existing functions here...\n",
    "print(\"Depth map generation functions loaded\")"
   ]
  }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "model_architecture"
   },
   "source": [
    "## 3. Multi-Task Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "model_config"
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ModelConfig:\n",
    "    \"\"\"Configuration for the wave analysis model.\"\"\"\n",
    "    backbone: str = 'convnext_base'\n",
    "    input_size: Tuple[int, int] = (768, 768)\n",
    "    feature_dim: int = 1024  # ConvNeXt-Base feature dimension\n",
    "    hidden_dim: int = 512\n",
    "    dropout_rate: float = 0.1\n",
    "    num_wave_types: int = 4  # A-frame, closeout, beach break, point break\n",
    "    num_directions: int = 3  # left, right, both\n",
    "    \n",
    "    # Training config\n",
    "    learning_rate: float = 1e-4\n",
    "    batch_size: int = 16  # Optimized for Colab GPU memory\n",
    "    num_epochs: int = 100\n",
    "    weight_decay: float = 1e-4\n",
    "    \n",
    "config = ModelConfig()\n",
    "print(f\"Model configuration: {config}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wave_analysis_model"
   },
   "outputs": [],
   "source": [
    "class WaveAnalysisModel(nn.Module):\n",
    "    \"\"\"Multi-task model for wave parameter extraction.\"\"\"\n",
    "    \n",
    "    def __init__(self, config: ModelConfig):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        \n",
    "        # Shared backbone (ConvNeXt)\n",
    "        self.backbone = timm.create_model(\n",
    "            config.backbone,\n",
    "            pretrained=True,\n",
    "            num_classes=0,  # Remove classification head\n",
    "            global_pool='avg'\n",
    "        )\n",
    "        \n",
    "        # Get feature dimension from backbone\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.randn(1, 3, *config.input_size)\n",
    "            features = self.backbone(dummy_input)\n",
    "            self.feature_dim = features.shape[1]\n",
    "        \n",
    "        # Task-specific heads\n",
    "        self.height_head = nn.Sequential(\n",
    "            nn.Linear(self.feature_dim, config.hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(config.dropout_rate),\n",
    "            nn.Linear(config.hidden_dim, 1)\n",
    "        )\n",
    "        \n",
    "        self.wave_type_head = nn.Sequential(\n",
    "            nn.Linear(self.feature_dim, config.hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(config.dropout_rate),\n",
    "            nn.Linear(config.hidden_dim, config.num_wave_types)\n",
    "        )\n",
    "        \n",
    "        self.direction_head = nn.Sequential(\n",
    "            nn.Linear(self.feature_dim, config.hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(config.dropout_rate),\n",
    "            nn.Linear(config.hidden_dim, config.num_directions)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Extract shared features\n",
    "        features = self.backbone(x)\n",
    "        \n",
    "        # Task-specific predictions\n",
    "        height = self.height_head(features).squeeze(-1)  # (batch_size,)\n",
    "        wave_type_logits = self.wave_type_head(features)  # (batch_size, 4)\n",
    "        direction_logits = self.direction_head(features)  # (batch_size, 3)\n",
    "        \n",
    "        return {\n",
    "            'height': height,\n",
    "            'wave_type_logits': wave_type_logits,\n",
    "            'direction_logits': direction_logits,\n",
    "            'wave_type_probs': torch.softmax(wave_type_logits, dim=1),\n",
    "            'direction_probs': torch.softmax(direction_logits, dim=1)\n",
    "        }\n",
    "\n",
    "# Create model and move to device\n",
    "model = WaveAnalysisModel(config).to(device)\n",
    "print(f\"Model created with {sum(p.numel() for p in model.parameters()):,} parameters\")\n",
    "print(f\"Feature dimension: {model.feature_dim}\")"
   ]
  }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "multi_task_loss"
   },
   "outputs": [],
   "source": [
    "class MultiTaskLoss(nn.Module):\n",
    "    \"\"\"Multi-task loss with learnable weights.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Learnable loss weights (initialized to 1.0)\n",
    "        self.height_weight = nn.Parameter(torch.tensor(1.0))\n",
    "        self.wave_type_weight = nn.Parameter(torch.tensor(1.0))\n",
    "        self.direction_weight = nn.Parameter(torch.tensor(1.0))\n",
    "        \n",
    "        # Individual loss functions\n",
    "        self.height_loss = nn.SmoothL1Loss()  # Robust to outliers\n",
    "        self.wave_type_loss = nn.CrossEntropyLoss()\n",
    "        self.direction_loss = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self, predictions, targets):\n",
    "        # Individual losses\n",
    "        height_loss = self.height_loss(predictions['height'], targets['height'])\n",
    "        wave_type_loss = self.wave_type_loss(predictions['wave_type_logits'], targets['wave_type'])\n",
    "        direction_loss = self.direction_loss(predictions['direction_logits'], targets['direction'])\n",
    "        \n",
    "        # Weighted combination\n",
    "        total_loss = (\n",
    "            self.height_weight * height_loss +\n",
    "            self.wave_type_weight * wave_type_loss +\n",
    "            self.direction_weight * direction_loss\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'total_loss': total_loss,\n",
    "            'height_loss': height_loss,\n",
    "            'wave_type_loss': wave_type_loss,\n",
    "            'direction_loss': direction_loss,\n",
    "            'weights': {\n",
    "                'height': self.height_weight.item(),\n",
    "                'wave_type': self.wave_type_weight.item(),\n",
    "                'direction': self.direction_weight.item()\n",
    "            }\n",
    "        }\n",
    "\n",
    "# Create loss function\n",
    "criterion = MultiTaskLoss().to(device)\n",
    "print(\"Multi-task loss function created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "property_tests"
   },
   "source": [
    "## 4. Property-Based Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "property_tests_code"
   },
   "outputs": [],
   "source": [
    "from hypothesis import given, strategies as st\n",
    "import hypothesis.extra.numpy as hnp\n",
    "\n",
    "def test_model_properties():\n",
    "    \"\"\"Property tests for model architecture.\"\"\"\n",
    "    \n",
    "    # Property 1: Model Input/Output Consistency\n",
    "    @given(batch_size=st.integers(min_value=1, max_value=4))\n",
    "    def test_input_output_consistency(batch_size):\n",
    "        \"\"\"Feature: wave-analysis-model, Property 1: Model Input/Output Consistency\"\"\"\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            # Generate random input\n",
    "            x = torch.randn(batch_size, 3, 768, 768).to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(x)\n",
    "            \n",
    "            # Check outputs exist and have correct shapes\n",
    "            assert 'height' in outputs\n",
    "            assert 'wave_type_logits' in outputs\n",
    "            assert 'direction_logits' in outputs\n",
    "            assert 'wave_type_probs' in outputs\n",
    "            assert 'direction_probs' in outputs\n",
    "            \n",
    "            # Check shapes\n",
    "            assert outputs['height'].shape == (batch_size,)\n",
    "            assert outputs['wave_type_logits'].shape == (batch_size, 4)\n",
    "            assert outputs['direction_logits'].shape == (batch_size, 3)\n",
    "            assert outputs['wave_type_probs'].shape == (batch_size, 4)\n",
    "            assert outputs['direction_probs'].shape == (batch_size, 3)\n",
    "    \n",
    "    # Property 3: Probability Vector Validity\n",
    "    @given(batch_size=st.integers(min_value=1, max_value=4))\n",
    "    def test_probability_validity(batch_size):\n",
    "        \"\"\"Feature: wave-analysis-model, Property 3: Probability Vector Validity\"\"\"\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            x = torch.randn(batch_size, 3, 768, 768).to(device)\n",
    "            outputs = model(x)\n",
    "            \n",
    "            # Check probabilities sum to 1\n",
    "            wave_type_sums = outputs['wave_type_probs'].sum(dim=1)\n",
    "            direction_sums = outputs['direction_probs'].sum(dim=1)\n",
    "            \n",
    "            assert torch.allclose(wave_type_sums, torch.ones_like(wave_type_sums), atol=1e-6)\n",
    "            assert torch.allclose(direction_sums, torch.ones_like(direction_sums), atol=1e-6)\n",
    "            \n",
    "            # Check probabilities are non-negative\n",
    "            assert (outputs['wave_type_probs'] >= 0).all()\n",
    "            assert (outputs['direction_probs'] >= 0).all()\n",
    "    \n",
    "    # Run tests\n",
    "    try:\n",
    "        test_input_output_consistency()\n",
    "        test_probability_validity()\n",
    "        print(\"✅ All model property tests passed!\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Property test failed: {e}\")\n",
    "\n",
    "# Run property tests\n",
    "test_model_properties()"
   ]
  }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data_pipeline"
   },
   "source": [
    "## 5. Data Pipeline and Synthetic Dataset Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wave_parameters"
   },
   "outputs": [],
   "source": [
    "# Wave parameter definitions\n",
    "WAVE_TYPES = ['A_FRAME', 'CLOSEOUT', 'BEACH_BREAK', 'POINT_BREAK']\n",
    "DIRECTIONS = ['LEFT', 'RIGHT', 'BOTH']\n",
    "BREAKING_TYPES = ['spilling', 'plunging', 'surging']\n",
    "\n",
    "# Create label mappings\n",
    "wave_type_to_idx = {wt: i for i, wt in enumerate(WAVE_TYPES)}\n",
    "direction_to_idx = {d: i for i, d in enumerate(DIRECTIONS)}\n",
    "breaking_to_wave_type = {\n",
    "    'spilling': 'BEACH_BREAK',\n",
    "    'plunging': 'A_FRAME', \n",
    "    'surging': 'CLOSEOUT'\n",
    "}\n",
    "\n",
    "print(f\"Wave types: {WAVE_TYPES}\")\n",
    "print(f\"Directions: {DIRECTIONS}\")\n",
    "print(f\"Breaking types: {BREAKING_TYPES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "synthetic_data_generator"
   },
   "outputs": [],
   "source": [
    "class SyntheticDataGenerator:\n",
    "    \"\"\"Generate synthetic wave data with ground truth labels.\"\"\"\n",
    "    \n",
    "    def __init__(self, output_size=(768, 768)):\n",
    "        self.output_size = output_size\n",
    "        self.rng = np.random.default_rng()\n",
    "        \n",
    "    def generate_wave_parameters(self):\n",
    "        \"\"\"Generate random but realistic wave parameters.\"\"\"\n",
    "        # Random wave height (0.3 to 4.0 meters)\n",
    "        height = self.rng.uniform(0.3, 4.0)\n",
    "        \n",
    "        # Random breaking type\n",
    "        breaking_type = self.rng.choice(BREAKING_TYPES)\n",
    "        wave_type = breaking_to_wave_type[breaking_type]\n",
    "        \n",
    "        # Random direction\n",
    "        direction = self.rng.choice(DIRECTIONS)\n",
    "        \n",
    "        # Generate wave components based on height\n",
    "        num_waves = self.rng.integers(2, 5)\n",
    "        wave_params = []\n",
    "        \n",
    "        for i in range(num_waves):\n",
    "            # Scale amplitude with total height\n",
    "            amp = height * self.rng.uniform(0.2, 0.8) / num_waves\n",
    "            wavelength = self.rng.uniform(8.0, 25.0)\n",
    "            direction_rad = self.rng.uniform(-np.pi/3, np.pi/3)\n",
    "            phase = self.rng.uniform(0, 2*np.pi)\n",
    "            speed = self.rng.uniform(2.0, 6.0)\n",
    "            \n",
    "            wave_params.append({\n",
    "                'amp': amp,\n",
    "                'wavelength': wavelength,\n",
    "                'direction': direction_rad,\n",
    "                'phase': phase,\n",
    "                'speed': speed\n",
    "            })\n",
    "        \n",
    "        return {\n",
    "            'height_meters': height,\n",
    "            'wave_type': wave_type,\n",
    "            'direction': direction,\n",
    "            'breaking_type': breaking_type,\n",
    "            'wave_params': wave_params\n",
    "        }\n",
    "    \n",
    "    def generate_depth_map(self, params):\n",
    "        \"\"\"Generate depth map from wave parameters.\"\"\"\n",
    "        # Use existing depth map generation (simplified version)\n",
    "        # This would integrate with your existing generate_beach_depth_map function\n",
    "        \n",
    "        # For now, create a placeholder that simulates the process\n",
    "        depth_map = np.random.randn(*self.output_size).astype(np.float32)\n",
    "        \n",
    "        # Add wave-like patterns based on parameters\n",
    "        x = np.linspace(-1, 1, self.output_size[1])\n",
    "        y = np.linspace(-1, 1, self.output_size[0])\n",
    "        X, Y = np.meshgrid(x, y)\n",
    "        \n",
    "        for wave in params['wave_params']:\n",
    "            k = 2 * np.pi / (wave['wavelength'] / 10)  # Scale for image\n",
    "            wave_pattern = wave['amp'] * np.sin(k * X + wave['phase'])\n",
    "            depth_map += wave_pattern\n",
    "        \n",
    "        return depth_map\n",
    "    \n",
    "    def depth_to_rgb(self, depth_map):\n",
    "        \"\"\"Convert depth map to RGB image (placeholder for ControlNet).\"\"\"\n",
    "        # Normalize depth map\n",
    "        depth_norm = (depth_map - depth_map.min()) / (depth_map.max() - depth_map.min() + 1e-8)\n",
    "        \n",
    "        # Create RGB image with wave-like colors\n",
    "        rgb = np.zeros((*depth_map.shape, 3), dtype=np.uint8)\n",
    "        \n",
    "        # Blue-green gradient for water\n",
    "        rgb[:, :, 0] = (depth_norm * 100).astype(np.uint8)  # Red\n",
    "        rgb[:, :, 1] = (depth_norm * 150 + 50).astype(np.uint8)  # Green\n",
    "        rgb[:, :, 2] = (depth_norm * 200 + 55).astype(np.uint8)  # Blue\n",
    "        \n",
    "        return rgb\n",
    "    \n",
    "    def generate_sample(self):\n",
    "        \"\"\"Generate a complete training sample.\"\"\"\n",
    "        # Generate parameters\n",
    "        params = self.generate_wave_parameters()\n",
    "        \n",
    "        # Generate depth map\n",
    "        depth_map = self.generate_depth_map(params)\n",
    "        \n",
    "        # Convert to RGB\n",
    "        rgb_image = self.depth_to_rgb(depth_map)\n",
    "        \n",
    "        # Create labels\n",
    "        labels = {\n",
    "            'height': params['height_meters'],\n",
    "            'wave_type': wave_type_to_idx[params['wave_type']],\n",
    "            'direction': direction_to_idx[params['direction']]\n",
    "        }\n",
    "        \n",
    "        return rgb_image, labels, params\n",
    "\n",
    "# Create data generator\n",
    "data_generator = SyntheticDataGenerator()\n",
    "print(\"Synthetic data generator created\")\n",
    "\n",
    "# Test generation\n",
    "sample_image, sample_labels, sample_params = data_generator.generate_sample()\n",
    "print(f\"Sample generated - Height: {sample_labels['height']:.2f}m, Type: {WAVE_TYPES[sample_labels['wave_type']]}, Direction: {DIRECTIONS[sample_labels['direction']]}\")"
   ]
  }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dataset_class"
   },
   "outputs": [],
   "source": [
    "class WaveDataset(Dataset):\n",
    "    \"\"\"Dataset for wave analysis training.\"\"\"\n",
    "    \n",
    "    def __init__(self, num_samples=1000, transform=None, generator_seed=None):\n",
    "        self.num_samples = num_samples\n",
    "        self.transform = transform\n",
    "        self.generator = SyntheticDataGenerator()\n",
    "        if generator_seed is not None:\n",
    "            self.generator.rng = np.random.default_rng(generator_seed)\n",
    "        \n",
    "        # Pre-generate samples for consistency\n",
    "        print(f\"Generating {num_samples} synthetic samples...\")\n",
    "        self.samples = []\n",
    "        for i in tqdm(range(num_samples)):\n",
    "            image, labels, params = self.generator.generate_sample()\n",
    "            self.samples.append((image, labels, params))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image, labels, params = self.samples[idx]\n",
    "        \n",
    "        # Convert to PIL Image for transforms\n",
    "        image = Image.fromarray(image)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # Convert labels to tensors\n",
    "        labels_tensor = {\n",
    "            'height': torch.tensor(labels['height'], dtype=torch.float32),\n",
    "            'wave_type': torch.tensor(labels['wave_type'], dtype=torch.long),\n",
    "            'direction': torch.tensor(labels['direction'], dtype=torch.long)\n",
    "        }\n",
    "        \n",
    "        return image, labels_tensor\n",
    "\n",
    "# Define transforms\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((768, 768)),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.15, saturation=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((768, 768)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "print(\"Dataset class and transforms defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "training"
   },
   "source": [
    "## 6. Training Pipeline with GPU Acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create_datasets"
   },
   "outputs": [],
   "source": [
    "# Create datasets (smaller for demo, increase for full training)\n",
    "print(\"Creating training dataset...\")\n",
    "train_dataset = WaveDataset(num_samples=1000, transform=train_transform, generator_seed=42)\n",
    "\n",
    "print(\"Creating validation dataset...\")\n",
    "val_dataset = WaveDataset(num_samples=200, transform=val_transform, generator_seed=123)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=config.batch_size, \n",
    "    shuffle=True, \n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=config.batch_size, \n",
    "    shuffle=False, \n",
    "    num_workers=2,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"Training batches: {len(train_loader)}\")\n",
    "print(f\"Validation batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "training_setup"
   },
   "outputs": [],
   "source": [
    "# Setup optimizer and scheduler\n",
    "optimizer = optim.AdamW(\n",
    "    model.parameters(), \n",
    "    lr=config.learning_rate, \n",
    "    weight_decay=config.weight_decay\n",
    ")\n",
    "\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer, \n",
    "    T_max=config.num_epochs\n",
    ")\n",
    "\n",
    "# Training tracking\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "print(\"Training setup complete\")"
   ]
  }